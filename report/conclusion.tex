\section{Conclusion}

In this project, we implemented a preprocessing pipeline designed to generate visual stimuli for artificial neural networks that more closely resemble those perceived by mice. After training AlexNet on the transformed ImageNet dataset, we evaluated its neural similarity to biological responses recorded in the Allen Neuropixels dataset.

Our results demonstrate that the data diet--that is, the preprocessing strategy--has a significant impact on neural predictivity compared to models trained without it. Notably, we observed a distinct and pronounced effect of the inference-time data relative to the training-time data. One possible explanation, considering the dot-product relationship between weights and input signals, is that the transformed stimuli themselves contribute more directly to neural predictivity than the weights optimized on such data. In other words, the mouse-like transformations applied at inference may be the primary drivers of alignment with biological neural activity. This finding raises an intriguing hypothesis: could inference-time transformations alone suffice to adapt a generic model such as AlexNet into an effective ``virtual brain'' for different species, by merely modifying its ``artificial retina''?

Two additional observations merit attention. First, the Nayebi's diet shows strong effects in the first convolutional layer, suggesting that TODO. Second, while untrained models lose neural predictivity when a diet is applied, trained models benefit from itâ€”indicating that the data diet interacts meaningfully with learned representations. Further analyses are needed to explore these directions and to better understand how ecological preprocessing shapes the neural alignment of artificial and biological systems.