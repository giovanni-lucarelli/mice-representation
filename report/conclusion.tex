\section{Discussion}

In this project, we developed a biologically-informed preprocessing pipeline to feed visual stimuli to artificial neural networks that more closely resemble those perceived by mice. We trained AlexNet on the transformed ImageNet dataset and evaluated its neural similarity to biological responses recorded in the Allen Neuropixels dataset. 

Our results demonstrate that the ecological data diet, \textit{i.e.}, the one obtained by our preprocessing strategy, provided both at training and inference time, provides the largest neural predictivity for all visual areas adn for all convolutional layers of AlexNet, except for the first one(see \cref{fig:rsa-vsrandom}). We note also that in all visual areas the peaks in neural predictivity are always in layers \texttt{conv2}, \texttt{conv3}. Therefore, we do not have evidence of a hierarchical structure in the mouse visual cortex, as already stated by Nayebi \textit{et al.} 

We also observed a clear decoupling effect, in the neural predictivity score, if the diet is provided at training or at inference time (see \cref{fig:inference}). While all tested data diets improved the predictivity of pretrained models, they consistently decreased the predictivity of untrained networks with random weights (see \cref{fig:random}). This indicates that the diet engages meaningfully with learned feature representions. In the case of trained models (both with diet and without) the inference time diet always improves the score, but with a clear larger impact on the model trained on unprocessed images, leading to a score almost always close to the one obtained by the model trained on preprocessed images (see \cref{fig:inference}). 

Finally, our attempt to replicate the pseudo-diet proposed by Nayebi--applied in our analysis only at inference time--indicates that the rescaling procedure serves as a reasonable, though not fully optimal, proxy for an ecological diet. Notably, this pseudo-diet yields the highest predictivity scores in the first convolutional layer. This outcome may arise from the construction of the pseudo-diet itself: the rescaling is performed via interpolation, which preserves spatial information, whereas the ecological diet employs a random resize-crop operation that can remove or distort spatial structure. Because the predictivity metric is based on Pearson correlation, any loss of spatial information can eliminate sources of explainable variance. This likely contributes to the decreased performance observed in \texttt{conv1}, a layer whose responses are strongly dependent on the precise spatial arrangement of the input by design.

Our overarching goal was to identify a model of the mouse visual system that incorporates the animal's natural visual experience. For this reason, we considered the model trained and evaluated with the ecological diet as our reference point, as it consistently processes mouse-like images. Surprisingly, however, most of the improvement in neural alignment originates at inference time: even a network trained on standard high-acuity images shows substantially increased predictivity once mouse-like transformations are applied to its inputs. This suggests that inference-time preprocessing may be the primary driver of alignment with biological neural activity. Consequently, an intriguing possibility emerges: perhaps modifying only the ``artificial retina''—the transformations applied at inference—could be sufficient to repurpose a generic vision model such as AlexNet into a plausible ``virtual brain'' for different species.

Together these findings highlight the importance of stimulus realism in brain-model correspondence analysis. They also reveal that even simple manipulations of input distributions can substantially alter these measurements. Further analyses should explore these directions to better understand how ecological preprocessing shapes the neural alignment of artificial and biological systems.