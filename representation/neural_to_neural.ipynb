{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e49787b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import (\n",
    "    get_areas, \n",
    "    get_specimen_ids, \n",
    "    get_trials,\n",
    "    get_units_count,\n",
    "    get_summary_df,\n",
    "    load_index\n",
    ")\n",
    "\n",
    "from mapping import (\n",
    "    consistency_across_trials,\n",
    "    interanimal_consistency_1v1,\n",
    "    interanimal_consistency_pool\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0553388",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_df = load_index(\"../Preproc2/data/combined_index.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9795ba",
   "metadata": {},
   "source": [
    "# Theoretical background\n",
    "\n",
    "## General framework\n",
    "\n",
    "The mouse representation after each stimulus (i.e. image) are stored in tensors of shape $(T, I, U)$, where:\n",
    "- $T$ is the number of trials (i.e. repetitions of the same stimulus)\n",
    "- $I$ is the number of images (i.e. different stimuli)\n",
    "- $U$ is the number of units (i.e. neurons) in a pairt (specimen, area)\n",
    "\n",
    "\n",
    "We want to compute the similarity between two representations, for example same (specimen, area) and different trials (fixed stimulus), or same area, different specimens (fixed stimulus), or the similarity between a model representation (e.g. one layer of AlexNet) and a (specimen, area) representation (fixed stimulus).\n",
    "\n",
    "\n",
    "## Corrected similarity\n",
    "\n",
    "In all cases we have to deal with very noisy signals, so we will use a statistical methods to estimate the **corrected similarity**, exploiting the repetitions of the same stimulus (trials).\n",
    "\n",
    "Let $A$ and $B$ be two representations of shape $(T, I, U_A)$ and $(T, I, U_B)$ respectively (e.g. $A$ could be a model representation, $B$ a neural representation, i.e. a specific specimen and area representation).\n",
    "\n",
    "$$\n",
    "\\text{sim}_\\text{corrected}(A,B) = \\frac{\\text{sim}_\\text{observed}(A,B)}{\\sqrt{\\text{reliability}(A) \\cdot \\text{reliability}(B)}}\n",
    "$$\n",
    "\n",
    "One way to estimate the reliability of a representation is to compute the similarity between two halves of the trials, for example using split-half correlation (Spearman-Brown corrected):\n",
    "\n",
    "$$\n",
    "\\text{reliability}(A) = \\text{SB}(\\text{sim}_\\text{observed}(A_1, A_2))\n",
    "$$\n",
    "$$\n",
    "\\text{SB}(r) = \\frac{2r}{1+r}\n",
    "$$\n",
    "\n",
    "where $A_1$ and $A_2$ are defined by taking two halves of the trials of representation $A$, and computing the mean response over trials for each half. So $A_1$ and $A_2$ have shape $(I, U_A)$, i.e. they are the traditional **design matrices**.\n",
    "\n",
    "The split is done by randomly assigning each trial to one of the two halves, and then averaging the similarity over multiple random splits (n_bootstrap=100).\n",
    "\n",
    "\n",
    "### RSA, CKA similarity\n",
    "\n",
    "$$\n",
    "\\text{RSA}_{\\text{corrected}}(A,B) = \\frac{\\frac{1}{2}[\\text{RSA}_{\\text{observed}}(A_1,B_2) + \\text{RSA}_{\\text{observed}}(A_2,B_1)]}{\\sqrt{\\text{reliability}(A) \\cdot \\text{reliability}(B)}}\n",
    "$$\n",
    "\n",
    "analogously for CKA.\n",
    "\n",
    "### PLS regression\n",
    "\n",
    "Given two representations $A$ and $B$, we fit a PLS regression model to predict $B$ from $A$ (with 25 components, as in the paper), and then we compute the corrected correlation between the predicted $\\hat{B}$ and the true $B$.\n",
    "\n",
    "We performed a train-test split on the images (50% train, 50% test): $A_{train}, A_{test}, B_{train}, B_{test}$.\n",
    "\n",
    "We split each of the train and test sets in two halves of trials: $A_{train,1}, A_{train,2}, A_{test,1}, A_{test,2}, B_{train,1}, B_{train,2}, B_{test,1}, B_{test,2}$.\n",
    "\n",
    "We fit two PLS models: one on the first half of trials, one on the second half of trials: \n",
    "\n",
    "$$\n",
    "f_1: A_{train,1} \\rightarrow B_{train,1}\n",
    "$$\n",
    "\n",
    "$$\n",
    "f_2: A_{train,2} \\rightarrow B_{train,2}\n",
    "$$\n",
    "\n",
    "We use the two models to predict the two halves of the test set:\n",
    "\n",
    "$$\n",
    "\\hat{B}_1 = f_1(A_{test,1})\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\hat{B}_2 = f_2(A_{test,2})\n",
    "$$\n",
    "\n",
    "Then for each unit $j$ in $B$, we compute the corrected correlation between the predicted and true responses:\n",
    "\n",
    "$$\n",
    "s_j = \\frac{\\text{corr}(\\hat{B}_1^j, B_2^j)}{\\sqrt{\\text{SB}(\\text{corr}(\\hat{B}_1^j,\\hat{B}_2^j)) \\cdot \\text{SB}(\\text{corr}(B_1^j,B_2^j))}}\n",
    "\n",
    "$$\n",
    "\n",
    "Finally we take the median over all units:\n",
    "\n",
    "$$\n",
    "\\text{PLS}_{\\text{corrected}}(A,B) = \\text{median}_j(s_j)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8732bb73",
   "metadata": {},
   "source": [
    "## Comparing a mouse with itself across different areas\n",
    "\n",
    "Using the above formalism, we compute here the similarity between the representations each pair (specimen, area) and itself. This is just a trivial check to ensure that the code is working as expected, i.e. the similarity should be 1 (or very close to 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f4571f",
   "metadata": {},
   "outputs": [],
   "source": [
    "consistency_rsa = consistency_across_trials(index_df, sim_metric='RSA')\n",
    "consistency_rsa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53c2da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "consistency_cka = consistency_across_trials(index_df, sim_metric='CKA')\n",
    "consistency_cka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccdaa984",
   "metadata": {},
   "outputs": [],
   "source": [
    "consistency_PLS = consistency_across_trials(index_df, sim_metric='PLS')\n",
    "consistency_PLS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd50fd6f",
   "metadata": {},
   "source": [
    "# 1 vs 1 mapping: interanimal consistency\n",
    "\n",
    "Now we can compute the similarity between each pair ofdifferent specimens, for the same area. This is the inter-animal consistency, as defined in the paper. Then we aggregate the results by taking the median across all pairs of specimens, for each area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32ab276",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Area\n",
       "VISal    0.141053\n",
       "VISam    0.370069\n",
       "VISl     0.220156\n",
       "VISp     0.368811\n",
       "VISpm    0.296283\n",
       "VISrl    0.236091\n",
       "Name: Mean, dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interanimal_consistency_1v1_df_rsa = interanimal_consistency_1v1(index_df, sim_metric='RSA')\n",
    "interanimal_consistency_1v1_df_rsa.groupby('Area')['Mean'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7477615",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Area\n",
       "VISal    0.240776\n",
       "VISam    0.421605\n",
       "VISl     0.179323\n",
       "VISp     0.370068\n",
       "VISpm    0.313516\n",
       "VISrl    0.273806\n",
       "Name: Mean, dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interanimal_consistency_1v1_df_cka = interanimal_consistency_1v1(index_df, sim_metric='CKA')\n",
    "interanimal_consistency_1v1_df_cka.groupby('Area')['Mean'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e05dc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "interanimal_consistency_1v1_df_pls = interanimal_consistency_1v1(index_df, sim_metric='PLS')\n",
    "interanimal_consistency_1v1_df_pls.groupby('Area')['Mean'].median()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e975a5",
   "metadata": {},
   "source": [
    "## Pooling version\n",
    "\n",
    "In the pooling version, we compute the similarity between each specimen and the pooled representation of all the other specimens, for the same area. Then we aggregate the results by taking the median across all specimens, for each area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7f96fb07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Area\n",
       "VISal    0.295959\n",
       "VISam    0.497050\n",
       "VISl     0.336013\n",
       "VISp     0.564326\n",
       "VISpm    0.369788\n",
       "VISrl         NaN\n",
       "Name: Mean, dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iac_pool_rsa = interanimal_consistency_pool(index_df, sim_metric='RSA')\n",
    "iac_pool_rsa.groupby('Area')['Mean'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e7d311fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Area\n",
       "VISal    0.359935\n",
       "VISam    0.606050\n",
       "VISl     0.356315\n",
       "VISp     0.588925\n",
       "VISpm    0.402080\n",
       "VISrl         NaN\n",
       "Name: Mean, dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iac_pool_cka = interanimal_consistency_pool(index_df, sim_metric='CKA')\n",
    "iac_pool_cka.groupby('Area')['Mean'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8140e9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "iac_pool_pls = interanimal_consistency_pool(index_df, sim_metric='PLS')\n",
    "iac_pool_pls.groupby('Area')['Mean'].median()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mice-representation (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
