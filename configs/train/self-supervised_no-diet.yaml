data:
  batch_size: 256
  num_workers: 12
  train_split: 0.7
  val_split: 0.15
  split_seed: 42

train:
  self_supervised: true
  num_epochs: 200
  dropout_rate: 0.3
  
  optimizer:
    name: SGD
    params:
      lr: 0.03
      momentum: 0.9
      weight_decay: 1e-4

  scheduler:
    name: MultiStepLR
    params:
      milestones: [120, 160, 180]
      gamma: 0.1

  loss:
    name: InstanceDiscriminationLoss
    params:
      mode: static
      m: 16384 #8192 # 4096
      gamma: 0.5
      tau: 0.07
      embedding_dim: 128
      model_output_dim: 4096
      warmup_epochs: 1
      z_const: 15.30 #2.24 #1232.82
  
  checkpoint_sub_dir: self-supervised_no-diet

  save_every_n: 10

diet:
  grayscale: false
  blur: false
  noise: false