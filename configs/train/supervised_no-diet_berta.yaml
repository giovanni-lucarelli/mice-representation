# Config for Berta (Lab Computer)
data:
  batch_size: 512   # too few?
  num_workers: 22   # too many?

  # split ratios 
  # do we really need a test set?
  # anyway, split is ignored on ImageNet which has predefined splits
  train_split: 0.7
  val_split: 0.15
  split_seed: 42
  persistent_workers: true
  prefetch_factor: 8

train:
  self_supervised: false
  autocast: false
  num_epochs: 100
  dropout_rate: 0.3
  early_stopping_patience: 25 # it was 15, do we really need to stop it earlier?

  optimizer:
    name: SGD
    params:
      lr: 0.03
      momentum: 0.9
      weight_decay: 1e-4

  scheduler:
    name: MultiStepLR
    params:
      milestones: [25, 50, 75]
      gamma: 0.2

  loss:
    name: CrossEntropyLoss
    params:
      label_smoothing: 0.1

  checkpoint_sub_dir: supervised_no-diet_berta

  save_every_n: 10 # -> 10 tot ckpts?

diet:
  grayscale: false
  blur: false
  noise: false
